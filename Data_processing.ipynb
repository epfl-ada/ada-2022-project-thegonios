{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef93ec5-a990-41df-9f57-988e0048c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import ast\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd10004-97c1-4ded-8fa6-aa04b49aa74f",
   "metadata": {},
   "source": [
    "(!pip install -U scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c57563-208a-41ff-91cd-90928b4bff75",
   "metadata": {},
   "source": [
    "# **STEP 0: Data opening and preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0d5fd-f312-4585-888b-b49df98d62e0",
   "metadata": {},
   "source": [
    "The data in the CMU Movie Summary Corpus contains a collection of 42,306 movie plot summaries and metadata at both the movie level (including box office revenues, genre and date of release) and character level (including gender and estimated age):\n",
    "\n",
    "**Data:**\n",
    "1. `plot_summaries.txt.gz` [29 M]: Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.  Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary.\n",
    "2. `corenlp_plot_summaries.tar.gz` [628 M, separate download]: to downlaod if considered useful... The plot summaries from above, run through the Stanford CoreNLP pipeline (tagging, parsing, NER and coref). Each filename begins with the Wikipedia movie ID (which indexes into movie.metadata.tsv).\n",
    "\n",
    "**Metadata:**\n",
    "1. `movie.metadata.tsv.gz` [3.4 M]: Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "- Wikipedia movie ID\n",
    "- Freebase movie ID\n",
    "- Movie name\n",
    "- Movie release date\n",
    "- Movie box office revenue\n",
    "- Movie runtime\n",
    "- Movie languages (Freebase ID:name tuples)\n",
    "- Movie countries (Freebase ID:name tuples)\n",
    "- Movie genres (Freebase ID:name tuples)\n",
    "2. `character.metadata.tsv.gz` [14 M]: Metadata for 450,669 characters aligned to the movies above, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns:\n",
    "- Wikipedia movie ID\n",
    "- Freebase movie ID\n",
    "- Movie release date\n",
    "- Character name\n",
    "- Actor date of birth\n",
    "- Actor gender\n",
    "- Actor height (in meters)\n",
    "- Actor ethnicity (Freebase ID)\n",
    "- Actor name\n",
    "- Actor age at movie release\n",
    "- Freebase character/actor map ID\n",
    "- Freebase character ID\n",
    "- Freebase actor ID\n",
    "\n",
    "**Test data**:\n",
    "1. `tvtropes.clusters.txt`: 72 character types drawn from tvtropes.com, along with 501 instances of those types.  The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv.\n",
    "2. `name.clusters.txt`: 970 unique character names used in at least two different movies, along with 2,666 instances of those types. The ID field indexes into the Freebase character/actor map ID in character.metadata.tsv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8329af-cba4-41bd-8f16-0ddcf5cf155d",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acccdb2-154d-4fba-ae8a-b0e3d8906b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './MovieSummaries/'\n",
    "characters = pd.read_csv(data_folder + 'character.metadata.tsv', sep='\\t', header=None)\n",
    "movies = pd.read_csv(data_folder + 'movie.metadata.tsv', sep='\\t', header=None)\n",
    "plot_summaries = pd.read_csv(data_folder + 'plot_summaries.txt', sep='\\t', header=None)\n",
    "character_types = pd.read_csv(data_folder + 'tvtropes.clusters.txt', sep='\\t', header=None)\n",
    "name_clusters = pd.read_csv(data_folder + 'name.clusters.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db9e79-8a64-4f1f-9252-988d835903aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.columns =['Wikipedia_movie_ID', \n",
    "                     'Freebase_movie_ID', \n",
    "                     'Movie_release_date', \n",
    "                     'Character_name', \n",
    "                     'Actor_birth', \n",
    "                     'Actor_Gender', \n",
    "                     'Actor Height', \n",
    "                     'Actor_Ethnicity', \n",
    "                     'Actor_Name', \n",
    "                     'Age_at_movie_release', \n",
    "                     'Freebase_character_actor_map_ID', \n",
    "                     'Freebase_character_ID', \n",
    "                     'Freebase_actor_ID']\n",
    "\n",
    "movies.columns =['Wikipedia_movie_ID', \n",
    "                 'Freebase_movie_ID', \n",
    "                 'Name',\n",
    "                 'Release_date', \n",
    "                 'Box_office_revenue', \n",
    "                 'Runtime',\n",
    "                 'Languages', \n",
    "                 'Countries', \n",
    "                 'Genres']\n",
    "\n",
    "plot_summaries.columns =['Wikipedia_movie_ID', 'Summary']\n",
    "character_types.columns =['Type', 'Info']\n",
    "name_clusters.columns =['Character_name', 'Freebase_character_actor_map_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c499f",
   "metadata": {},
   "source": [
    "## Dataframes pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844dbc3d",
   "metadata": {},
   "source": [
    "### `characters` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5973fca",
   "metadata": {},
   "source": [
    "Each row is a character paired to an actor in a single movie, columns correspond to features that describe those characters, the actor that play them and the movie in which it happened. To get a better understanding, not that a single character can be played by multiple actor (e.g. James Bond) and that a single actor can have multiple roles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9959c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df39a71",
   "metadata": {},
   "source": [
    "Note that only the fetaures `Wikipedia_movie_ID`, `Freebase_movie_ID` and `Freebase_character_actor_map_ID` do not contain missing values. In particular we can see below that only `Freebase_character_actor_map_ID` values are all unique, in fact this mapping id are uniquely created for each single movie.Note also that the number of characters is lower than the number of actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce430e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "characters.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad1f0a",
   "metadata": {},
   "source": [
    "Below is a good example to understand the subtility of this dataframe. Each row contains the information of an actor that played a particular character in a particular movie. Thus if an actor as played a characters in n movies, their will be n rows to describe their relationship where apart the map id, only features related to the movie will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7363899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "characters.loc[characters.Actor_Name == 'Roger Moore'].query(\"Character_name == 'James Bond'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25c8f9",
   "metadata": {},
   "source": [
    "Now that we have understand the structure of the `characters` dataframe, we would like to retrieve the wikidata items corresponding to the freebase ids contained in `Actor_Ethnicity`. To do so we will use the wikidata query service through the sparqlwrapper package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694fe222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all freebase with format corresponding to the wikidata query service. Then manually copy pasted\n",
    "ethnicity_id = list(characters['Actor_Ethnicity'].value_counts().index)\n",
    "for e in ethnicity_id : print('\"'+e+'\"',end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://rdflib.github.io/sparqlwrapper/\n",
    "\n",
    "#Below the query is made in two steps to respect the maximal size of the function's capacity\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query1 = \"\"\"PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "SELECT DISTINCT ?id ?itemLabel WHERE {\n",
    "  VALUES ?id {\"/m/044038p\" \"/m/075_n6\" \"/m/0bbz66j\" \"/m/02rbdlq\" \"/m/0bkbz\" \"/m/01336l\" \"/m/04dbw3\" \"/m/0fqz6\" \"/m/06j2v\" \"/m/046cwm\" \"/m/0g6ff\" \"/m/0432mrk\" \"/m/0gkxl2\" \"/m/02p1pl6\" \"/m/03w9bjf\" \"/m/04tvpv\" \"/m/027n1m6\" \"/m/09743\" \"/m/0bhsnb\" \"/m/013b6_\" \"/m/048sp5\" \"/m/0h2138\" \"/m/02y_9mh\" \"/m/02jvpv\" \"/m/0dbxy\" \"/m/02vsw1\" \"/m/08cjt2\" \"/m/013s3n\" \"/m/09zyn5\" \"/m/0cm7w1\" \"/m/04q7gbh\" \"/m/0fj1k9\" \"/m/0fqp6zk\" \"/m/04f581\" \"/m/012c1l\" \"/m/071x0k\" \"/m/0ffjqy\" \"/m/0ffkb4\" \"/m/0g5y6\" \"/m/0bzkm2\" \"/m/0dllcfn\" \"/m/04y8_bm\" \"/m/03gskx0\" \"/m/0268d21\" \"/m/019lrz\" \"/m/02p4q5p\" \"/m/04czx7\" \"/m/02p656s\" \"/m/0ffhz3\" \"/m/04jq32s\" \"/m/04mmhj\" \"/m/0dj8k3\" \"/m/059_w\" \"/m/01kg2v\" \"/m/0222hg\" \"/m/0f0gt_\" \"/m/01j2qv\" \"/m/0ffjvd\" \"/m/032j30\" \"/m/033njm\" \"/m/0bs7l_v\" \"/m/0g48m4\" \"/m/022fdt\" \"/m/052r3t\" \"/m/0bfjm7\" \"/m/01xttr\" \"/m/04ydrsn\" \"/m/03295l\" \"/m/06lshc\" \"/m/03cbkrf\" \"/m/0283js_\" \"/m/09cqth\" \"/m/04nrnz\" \"/m/05748\" \"/m/025_0f0\" \"/m/01trsl\" \"/m/09vmyh\" \"/m/05sf2x\" \"/m/09gk_6h\" \"/m/078vc\" \"/m/01p7s6\" \"/m/017sq0\" \"/m/018s6c\" \"/m/04y29\" \"/m/067lts\" \"/m/05g0f1\" \"/m/0761bp\" \"/m/09gp4\" \"/m/02qv_h_\" \"/m/0640_7q\" \"/m/0912ll\" \"/m/013b7g\" \"/m/067lrj\" \"/m/0b79c7\" \"/m/09lz9zx\" \"/m/01swvz\" \"/m/01nbcy\" \"/m/0b0gzf\" \"/m/071drf\" \"/m/027vy0s\" \"/m/0150zs\" \"/m/0278pqj\" \"/m/0747611\" \"/m/0c2hxm\" \"/m/0462jl6\" \"/m/074w_m\" \"/m/04ggbzy\" \"/m/0hbz9xw\" \"/m/0152s7\" \"/m/0fng3k\" \"/m/0j4w_\" \"/m/0b98sy\" \"/m/08v2k7\" \"/m/0j6x8\" \"/m/0d9q7j\" \"/m/016f5d\" \"/m/0ffj5g\" \"/m/0338zd\" \"/m/04_tz7\" \"/m/027lf0d\" \"/m/0ch3pqf\" \"/m/06fczy\" \"/m/01mw1s\" \"/m/04608z\" \"/m/04_hr_\" \"/m/026cybk\" \"/m/01hwt\" \"/m/08gzsf\" \"/m/05vhv7\" \"/m/04_bc8\" \"/m/06rd7\" \"/m/0318mh\" \"/m/02wcbj_\" \"/m/0520604\" \"/m/07j80c\" \"/m/078ds\" \"/m/0fk1z\" \"/m/0dv5vw\" \"/m/04znbg\" \"/m/01sq7s\" \"/m/0gf5k1\" \"/m/03pqwy\" \"/m/031_sd\" \"/m/012f86\" \"/m/092h2qt\" \"/m/033qxt\" \"/m/03vghh\" \"/m/0bjbszh\" \"/m/07hyjp\" \"/m/03yk6g\" \"/m/0h1nk0k\" \"/m/04zjjt\" \"/m/02czfr\" \"/m/05qb937\" \"/m/047l_90\" \"/m/0bnzjx\" \"/m/02q206y\" \"/m/0665pp\" \"/m/07gzw5\" \"/m/062_25\" \"/m/0hj35\" \"/m/0bh91q8\" \"/m/01g0y_\" \"/m/07lv5x\" \"/m/0g4pffv\" \"/m/0828vj\" \"/m/07d_p8\" \"/m/04lhn7b\" \"/m/0fq6zlv\" \"/m/0268pvf\" \"/m/0466nw8\" \"/m/04pnf\" \"/m/02p_gby\" \"/m/06k6sl\" \"/m/0738n4\" \"/m/0266mf0\" \"/m/0cx3p\" \"/m/04kbvpz\" \"/m/07s9g04\" \"/m/04l_pt\" \"/m/026c9dq\" \"/m/01ylpf\" \"/m/0g5k7qv\" \"/m/01tyl3\" \"/m/0b__fv3\" \"/m/02vkd28\" \"/m/013s41\" \"/m/047948f\" \"/m/067lwk\" \"/m/03d19xz\" \"/m/02gx2x\" \"/m/021pd\" \"/m/013s2p\" \"/m/09fqz7\" \"/m/0ffhvl\" \"/m/075dhf0\" \"/m/02dd5z\" \"/m/03wbmrc\" \"/m/0br_8h\" \"/m/097nms\" \"/m/02cm28\" \"/m/0h6mqq9\" \"/m/09tqq8q\" \"/m/0301y_\" \"/m/0d8qh0\" \"/m/03h1dq9\" \"/m/03fk0c\" \"/m/026kx7g\" \"/m/04k02l\" \"/m/051wcch\" \"/m/026zlyd\" \"/m/01n94b\" \"/m/04dzwby\" \"/m/0btrm4\" \"/m/03ndvw\" \"/m/0fxmtg\" \"/m/04sfz4s\" \"/m/03cnzsg\" \"/m/03r_k\" \"/m/03f3sf\" \"/m/04lfc70\" \"/m/02vkw95\" \"/m/09y7x4\" \"/m/0fk3s\" \"/m/0h8mzsl\" \"/m/02p444n\" \"/m/03kbr\" \"/m/0bns36b\" \"/m/0bbcnlt\" \"/m/046j25\" \"/m/0dq1q\" \"/m/02rdfpy\" \"/m/05c60ml\" \"/m/0470lk\" \"/m/02p7gyv\" \"/m/0c29q8\" \"/m/03ck8x1\" \"/m/042199j\" \"/m/0bms44\" \"/m/01nft3\" \"/m/01d7kx\" \"/m/01c034\" \"/m/05cc9h\" \"/m/03cl2pz\" \"/m/03x_lpj\" \"/m/02rp50t\" \"/m/03m3p6w\" \"/m/02r_qms\" \"/m/086wp0\" \"/m/065z7w_\" \"/m/01f9bg\" \"/m/03sx6v\" \"/m/034s7b\" \"/m/0987ctr\" \"/m/03gy1h2\" \"/m/0c_lbq\" \"/m/03ftx7\" \"/m/067lv3\" \"/m/0g44f5\" \"/m/03d26m9\" \"/m/0165md\" \"/m/0dqrh8\" \"/m/0cc5y74\" \"/m/0289z8v\" \"/m/01267\" \"/m/0fpjs3j\" \"/m/03cdk7b\" \"/m/0bfrrj\" \"/m/04wy6k\" \"/m/03zcwh\" \"/m/0dc58y8\" \"/m/0g5rkt4\" \"/m/0647lm\" \"/m/04fh1b\" \"/m/047bp1r\" \"/m/09cd0m\" \"/m/03fvrb\" \"/m/025x6k1\" \"/m/02rm7_9\" \"/m/01l0ty\" \"/m/07s49c2\" \"/m/03ty8_\" \"/m/02m0kh\" \"/m/05ms3p0\" \"/m/0gtwjz6\" \"/m/0ftlzz\" \"/m/02pzb09\" \"/m/05sycg\" \"/m/051x6yk\" \"/m/01vsch\" \"/m/04csgrq\" \"/m/064b9n\" \"/m/09chmw\" \"/m/095mw2\" \"/m/09snp5\" \"/m/025tvhm\" \"/m/0c41n\" \"/m/01_5cg\" \"/m/025xss1\" \"/m/0404kdr\" \"/m/0ftwg\" \"/m/0790v\" \"/m/02r3wfk\" \"/m/03h11s3\" \"/m/01vr3v\" \"/m/0c3wsgg\" \"/m/06y24j\" \"/m/0ckk60\" \"/m/03lnnd\" \"/m/04hlx1\" \"/m/062zk4r\" \"/m/097r55\" \"/m/0b8yvr\" \"/m/0br_9j\" \"/m/0xff\" \"/m/01crfj\" \"/m/05mtdy\" \"/m/065577s\" \"/m/0fp4n\" \"/m/0301xt\" \"/m/01kb9y\" \"/m/0268xtg\" \"/m/05y2yj\" \"/m/0ffk5n\" \"/m/02vys3l\" \"/m/01h4n\" \"/m/0bvnws\" \"/m/06dy2k\" \"/m/08yg47\" \"/m/08c25t\" \"/m/0bvjpj\" \"/m/03x1x\" \"/m/0dn1_0\" \"/m/02qv716\" \"/m/02r11hz\" \"/m/06bkf\" \"/m/035b50\" \"/m/0166vx\" \"/m/01g3rx\" \"/m/06w4lv\" \"/m/04wysy\" \"/m/064pj\" \"/m/013z8m\" \"/m/04118b\" \"/m/064rb5l\" \"/m/01ywdy\" \"/m/01flqq\" \"/m/0960kn\" \"/m/0180zw\" \"/m/0463n9y\" \"/m/0d32d1\" \"/m/07n8wy\" \"/m/03q819\" \"/m/06vb7b\" \"/m/02pj9yr\" \"/m/03hf_6z\" \"/m/01km_m\" \"/m/062szv5\" \"/m/07g8yp\" \"/m/0fk55\" \"/m/04lgl9t\" \"/m/0444sm4\" \"/m/03m9my8\" \"/m/03cjjy0\" \"/m/03cmqbt\" \"/m/0b3zsn\" \"/m/03b_13l\" \"/m/0152wh\" \"/m/05ysft4\" \"/m/05sng\" \"/m/059v8\" \"/m/09c8kp\" \"/m/04jtjvt\" \"/m/04c28\" \"/m/03sk2\" \"/m/05ztd1\" \"/m/0dm3xpw\" \"/m/03hjx6f\" \"/m/026d074\" \"/m/03nvq\" \"/m/03nz70\" \"/m/029q52\" \"/m/02wz7j\" \"/m/04kdwcx\" \"/m/02ry8mk\" \"/m/07wsyr\" \"/m/09r2kh\" \"/m/04_8lfc\" \"/m/033qt1\" \"/m/012fh\" \"/m/08j1fb\" \"/m/027936c\" \"/m/0dtkkb\" \"/m/05bzpzx\" \"/m/04lhnps\" \"/m/0fp54b\" \"/m/01hm_\" \"/m/0288fw3\" \"/m/0ft9bs\" \"/m/01gr8h\" \"/m/09g34_\" \"/m/0d8qls\" \"/m/08xbxs\" \"/m/032m0b\" \"/m/04hqxn\" \"/m/068y7m\" \"/m/044bp_\" \"/m/039z49\" \"/m/047q05d\" \"/m/0c50f\" \"/m/01srl7\" \"/m/0fpxlz9\" \"/m/0bdynxs\" \"/m/01gby2\" \"/m/043_z22\" \"/m/03x_fq7\" \"/m/01hphz\" \"/m/033fjj\" \"/m/013y54\"}.\n",
    "   ?item wdt:P646 ?id.\n",
    "    \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "SELECT DISTINCT ?id ?itemLabel WHERE {\n",
    "  VALUES ?id {\"/m/0dryh9k\" \"/m/0x67\" \"/m/041rx\" \"/m/02w7gg\" \"/m/033tf_\" \"/m/0xnvg\" \"/m/02ctzb\" \"/m/07hwkr\" \"/m/07bch9\" \"/m/044038p\" \"/m/03bkbh\" \"/m/0d7wh\" \"/m/03ts0c\" \"/m/0222qb\" \"/m/01rv7x\" \"/m/02sch9\" \"/m/04mvp8\" \"/m/03lmx1\" \"/m/065b6q\" \"/m/01qhm_\" \"/m/06mvq\" \"/m/048z7l\" \"/m/0bpjh3\" \"/m/0cqgdq\" \"/m/0g8_vp\" \"/m/09vc4s\" \"/m/013xrm\" \"/m/019kn7\" \"/m/06gbnc\" \"/m/07mqps\" \"/m/01g7zj\" \"/m/01xhh5\" \"/m/03bx0k4\" \"/m/0g96wd\" \"/m/02g7sp\" \"/m/09m6hr\" \"/m/063k3h\" \"/m/0g0x7_\" \"/m/03ttfc\" \"/m/023mqw\" \"/m/0d2by\" \"/m/09kr66\" \"/m/042gtr\" \"/m/025rpb0\" \"/m/08hpk0\" \"/m/038723\" \"/m/0583cz\" \"/m/022dp5\" \"/m/0cmdl5l\" \"/m/03vv99\" \"/m/029f2r\" \"/m/09k5jvk\" \"/m/0cnvdq1\" \"/m/06v41q\" \"/m/04gfy7\" \"/m/0bymc\" \"/m/0cn68\" \"/m/09v5bdn\" \"/m/05l3g_\" \"/m/0268_k\" \"/m/0dqqwy\" }.\n",
    "   ?item wdt:P646 ?id.\n",
    "    \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "results1 = get_results(endpoint_url, query1)\n",
    "results2 = get_results(endpoint_url, query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results1[\"results\"][\"bindings\"]:\n",
    "    characters['Actor_Ethnicity'].replace(result['id']['value'],result['itemLabel']['value'],inplace=True)\n",
    "\n",
    "for result in results2[\"results\"][\"bindings\"]:\n",
    "    characters['Actor_Ethnicity'].replace(result['id']['value'],result['itemLabel']['value'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d989d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.Actor_Ethnicity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e28bdd",
   "metadata": {},
   "source": [
    "Preprocessing ends here for the `characters` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682f4ba",
   "metadata": {},
   "source": [
    "### `movies`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba13653",
   "metadata": {},
   "source": [
    "Each row is a movie, columns correpsond to features that describe those movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4257894",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a974d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda44158",
   "metadata": {},
   "source": [
    "Here we can observe that columns `Release_date`, `Box_office_revenue` and `Runtime` each have a certain number of null values. In order to keep a maximum information, we will not drop all movies having at least one null value in their features because we could still have use of other features independently. However, the null values will be handled when working on particular features with subsets of the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa45b4",
   "metadata": {},
   "source": [
    "Note that the `Release_date` feature column Dtype is 'object'. To handle the date in a simpler way with panda DataFrames we would like to use the DateTime type. The transformation is done below. Note that after a first try, we found that the value of movie 62836 in the dataframe had a non-valid syntax, thus we changed its value manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc400b40-ae27-4c40-acfe-0dfcb8383c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.iloc[62836,3] =  pd.to_datetime('2010-12-02')\n",
    "movies.loc[:,['Release_date']] = pd.to_datetime(movies['Release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a888a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies.Release_date.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82018ac3",
   "metadata": {},
   "source": [
    "Now the `Release_date`Dtype is datetime64 and we see that the number of null values is still the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95534f7d",
   "metadata": {},
   "source": [
    "Columns `Languages`, `Countries` and `Genres` have a special format. Even if they are stored as string, we can recognize dictionnaries. The keys are the freebase ID of the wikidata item contained in the corresponding dictionnaries' values. Here we are not interested in keeping the freebase id, thus we only retrieve the values using the regex `re` library. We can also create lists of genres for each movie instead of a long string in the `Genres` column. This pre-processing is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:,['Genres']] = movies[['Genres']].applymap(ast.literal_eval) # transform string -> dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dicts(arg):\n",
    "    return list(arg.values())\n",
    "\n",
    "movies[['Genres']] = movies[['Genres']].applymap(replace_dicts) # transform dict -> list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Languages'] = movies['Languages'].apply(lambda x: re.findall('\": \"(.*)\"', x)).str[0] # string -> string\n",
    "movies['Countries'] = movies['Countries'].apply(lambda x: re.findall('\": \"(.*)\"', x)).str[0] # string -> string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf66b6",
   "metadata": {},
   "source": [
    "Preprocessing ends here for the `movies` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354cea2",
   "metadata": {},
   "source": [
    "### `plot_summaries`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a8125",
   "metadata": {},
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d0e0f-843a-4817-8e6c-860bebf8143b",
   "metadata": {},
   "source": [
    "### `character_types`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace521f4",
   "metadata": {},
   "source": [
    "to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64a00c-c18d-4dbc-9153-03c255c10b25",
   "metadata": {},
   "source": [
    "In the `character_types` dataframe above, the `Info` column contains long strings that give information about the character that the character type describes, the movie in which the character is found, the Freebase character/actor map ID and the actor that embodies the character. All of this information can be separated into four disctint columns: character, movie, ID and actor columns, using the `json` library as below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0f336-07e5-4027-9499-9b34271e437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_types[['char', 'movie', 'Freebase_character_actor_map_ID', 'actor']] = character_types['Info'].apply(lambda x: json.loads(x)).apply(pd.Series)\n",
    "character_types.drop('Info', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4cc50",
   "metadata": {},
   "source": [
    "### `name_clusters`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb218087",
   "metadata": {},
   "source": [
    "to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6530cf-da9b-443f-a363-915ffbc52d71",
   "metadata": {},
   "source": [
    "### first Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26e334-5c07-48e7-8412-d9ac3038a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Movies dataframe has {len(movies)} rows')\n",
    "print(f'Characters dataframe has {len(characters)} rows')\n",
    "print(f'Plot_summaries dataframe has {len(plot_summaries)} rows')\n",
    "print(f'Character_types dataframe has {len(character_types)} rows')\n",
    "print(f'Name_clusters dataframe has {len(name_clusters)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ddbb3-b70c-48dc-b92b-475421268391",
   "metadata": {},
   "source": [
    "Therefore, each of our da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5280f-ca55-4af7-8140-ce6cd0356fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_datetime=movies.dropna()\n",
    "movies_datetime = movies_datetime.groupby((pd.to_datetime(movies_datetime['Release_date']).dt.to_period('Y'))).apply(lambda x: pd.Series({\n",
    "    'mean_runtime': x['Runtime'].mean(),\n",
    "    'mean_box_office_revenue': x['Box_office_revenue'].mean(),\n",
    "    'num_movies': len(x),\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_datetime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42526aa-62ac-424b-bb20-d03e2ee0dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_datetime.num_movies.plot(grid=True, label=\"number of film\", legend=True)\n",
    "movies_datetime.mean_box_office_revenue.plot(secondary_y=True, label=\"mean box office revenue\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b1870-510c-4070-bdbd-6f9745561678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Movie year of release span from {movies_datetime.index.min()} to {movies_datetime.index.max()}.')\n",
    "print('Our dataset have', (movies_datetime.num_movies==0).sum(), ' year(s) where no films where released.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc082e6c-aa79-46da-9144-9286add1e252",
   "metadata": {},
   "source": [
    "Since there is not any year without a movie release, any distribution of a movie characteristic will be continuous over time and will thus be possible to analyze. Moreover, we can think to have some correlation between the number of movies and the box office revenue. However, with this first plot, we cannot conclude something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb14468-1423-44db-a1c6-63fbafc75d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_datetime.num_movies.plot(grid=True, label=\"number of film\", legend=True)\n",
    "movies_datetime.mean_runtime.plot(secondary_y=True, label=\"mean runtime\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a86c21-924a-4bb9-817b-f49bfb7cfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(movies_datetime.mean_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea60fd7-5d97-46e1-9abf-85800a8eb07b",
   "metadata": {},
   "source": [
    "Here, we can see that the runtime fluctuated during the first 50th years but then the runtime is around 100min with less fluctuation with time. However this a good example of the attention we will have to pay to the 'weights' through the years. Indeed during first 50th years there are a lot of fluctuations of the mean runtime but the fact that these years contains only a few movies make it difficult to estimate a global tendency. Maybe these years should be grouped. In comparison, the fluctuation is less important during the last 50 years but the samples size by year are larger, thus it follows by law of large numbers that the means will be closer to the expected value (the reasoning is valable if we assume that the expected mean runtime is the same for each year)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aac947-9d37-4bbc-9aed-b946fa77347f",
   "metadata": {},
   "source": [
    "*A voir si c'est utile d'ajouter les plots directement au movie dataset...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942e9a4-6863-456f-929c-c4ca63872fcd",
   "metadata": {},
   "source": [
    "### Some data combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89197c17-26b2-44f8-919a-68a255a07aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_plot = movies.merge(plot_summaries, on=\"Wikipedia_movie_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bbacd-7654-47e7-8923-3d473850dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_characters_type = pd.merge(characters, character_types, on='Freebase_character_actor_map_ID', suffixes=('', '_y'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba479cd-e94f-4db8-9a65-c8d818481e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_characters_type.drop(['char','actor'],axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea85677-0ab8-474f-a4a0-848013074b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_characters_type = pd.merge(merge_characters_type, movies[['Wikipedia_movie_ID', 'Languages', 'Countries', 'Genres', 'Box_office_revenue', 'Runtime']], on='Wikipedia_movie_ID', suffixes=('', '_y'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe22a7f-670d-4e05-acd1-804324de78d3",
   "metadata": {},
   "source": [
    "# **STEP 1: dictionnary definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bc14a-e4bc-4230-900e-ef84d1b16a1d",
   "metadata": {},
   "source": [
    "Trick: could add spaces in front of words that are ambiguous. Example below with SS: a lot of words contain the sequence ss, but space+ss is rare. We could even consider space+ss++space, but this would exclude some occurances due to punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05ec33-9d0e-46f8-b302-7848a8c5812c",
   "metadata": {},
   "source": [
    "### Worl War 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecfd49-5875-41b4-ae5e-5c75f187d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WW1 =  ['WW1', 'World War 1', '1914', '1918', 'Allies', 'armistice', 'Central Powers', 'conscription', 'front line', 'Joffre', 'Kaiser', 'Marne',\n",
    "        'mustard gas', 'no man’s land', 'Pétain', 'u boats', 'Somme', 'Tommy', 'Treaty of Versailles', 'trench', 'Verdun', 'Western front', \n",
    "        'zeppelin', 'artillery', 'doughboy', 'duckboards', 'dreadnought', 'mobilize', 'Prussia', 'Schlieffen plan', 'Tsar', 'Archduke Ferdinand',\n",
    "        'Red Baron', 'big four', 'Christmas truce', 'Wilson', 'Lusitania', 'Battalion', 'triple entente', 'Great War', 'flamethrower', 'mills bomb',\n",
    "        'storm troop', 'ace', 'recco', 'tailspin', 'boche', 'wipers', 'kiwi', 'Sammy', 'Aussie', 'cootie', 'Flanders', 'mud', 'war effort', \n",
    "        'League of Nations']\n",
    "WW1 = [x.lower() for x in WW1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9f120-92a5-400e-bcd6-b8d9f59216ab",
   "metadata": {},
   "source": [
    "### World War 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489f511-02e8-4d62-88e7-8e6592ff787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WW2 =  ['Allies','Auschwitz','Bombardment', 'battleship', 'Bailey bridge', 'Blitzkrieg','Churchill','D-Day',' ss'\n",
    "        'Dunkirk', 'Doolittle', 'de Gaulle','English Channel', 'Eisenhower','Enigma','flying tigers', 'free french',\n",
    "        'nazi','helmet','Hiroshima','Invasion','Luftwaffe','Manhattan Project', 'Midway','Pearl harbor','Normandy', 'Nagasaki',\n",
    "        'Panzer','Roosevelt', 'Rangers','Resistance','Truman', 'Stalin', 'tank','Victory', 'V-1 rocket','doodlebugs',\n",
    "        'World War II','ww2','Hitler','air raid','shelter','siren','Battle of Britain','evacuee','evacuation','gas mask',\n",
    "        'spitfire', '1939', '1945']\n",
    "WW2 = [x.lower() for x in WW2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef538fe2-b74e-4fc6-8473-bfae8da7ad50",
   "metadata": {},
   "source": [
    "### Space race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63dfb2-ac34-4704-9d63-cda86aa2313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Space = ['aeronautics','Alan Shepard','Apollo','Cape Canaveral','capitalism','Cold War','Communism','Gemini','heat shields', \n",
    "         'Houston','John Glenn','Laika','launch','Lunar Module','Mercury','Michael Collins','Mission Control','NASA','neil Armstrong',\n",
    "         'orbit','planet','rocket','satellite','Scott Carpenter','Sergei Korolev','solar system','space','space exploration','Space Race',\n",
    "         'Sputnik','superpowers','test pilot',' USA',' URSS','Yuri Gagarin']\n",
    "Space = [x.lower() for x in Space]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840d63f-640c-49b2-b5d4-59ffcad06a92",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32eeda-c87f-462e-afed-2164098410ee",
   "metadata": {},
   "source": [
    "If we do number of words, it could depend too much on the length of the plot summary or the length and quality of the dictionnary. Thus, a min-max scaling or standardization could be usefull afterward in the feature space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05d67d-aef4-4dbc-aa01-446562e9ad86",
   "metadata": {},
   "source": [
    "## ?on pourrait définir un % du numbre de mot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e08179-f87b-47a4-9d09-1b1d5ecb50c5",
   "metadata": {},
   "source": [
    "# **STEP 2: Apply dictionnaries to plot summaries to create new features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c4d16-f253-4a6e-afbd-4cad1e062f01",
   "metadata": {},
   "source": [
    "lower case every plot summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef2620-c889-4011-b28e-c850bbfdef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = movies_plot.Summary.apply(lambda h: h.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c1756-80b5-467c-aea9-90bbba331fb8",
   "metadata": {},
   "source": [
    "Count the number of times word from a given dictionnary occurs in a plot summary. This function creates a new column in the movies_plot DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f0103-410d-437d-9e82-9245be25d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dict(name,dictionnary):\n",
    "    movies_plot[name] = summaries.apply(lambda summary: np.sum([summary.count(word) for word in dictionnary]))\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4bca3-afd6-47f0-8ac5-95ef9604f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict('WW1',WW1)\n",
    "count_dict('WW2',WW2)\n",
    "count_dict('SpaceRace',Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd16db-e9d5-4f1f-9b66-f74921033bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_plot[movies_plot.WW2 > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73a7d7-fd48-4063-9e6e-889be28a42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2237372-45a4-43ee-883f-40924fe00f84",
   "metadata": {},
   "source": [
    "# **STEP 2: ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040c4a4-0226-4f38-a037-9a4bfe191016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary tresholds:\n",
    "ww1T = 5\n",
    "ww2T = 5\n",
    "SpaceT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364750b0-ac36-4e5d-a3aa-c0152b85f319",
   "metadata": {},
   "source": [
    "## w.r.t time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db549afa-5f1f-486a-8749-f78815e3f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_analysis(name,tresh,freq = '5y'):\n",
    "    analysis = movies_plot[movies_plot[name] > tresh].copy()\n",
    "    \n",
    "    analysis = analysis.groupby(pd.to_datetime(analysis['Release_date']).dt.to_period(freq = freq)).apply(lambda x:\n",
    "    #All kind of analysis:\n",
    "        pd.Series({\n",
    "            'number': x[name].count(),\n",
    "            'mean_revenue' : x['Box_office_revenue'].mean(),\n",
    "            'mean_runtime' : x['Runtime'].mean(),\n",
    "        })\n",
    "    )\n",
    "    return analysis\n",
    "\n",
    "#See how to plot better\n",
    "def plot_time_analysis(time_analysis,name):\n",
    "    time = time_analysis.index.to_timestamp()\n",
    "    for analysis in time_analysis.columns:\n",
    "        #plt.plot(time,reg.predict(x),'k-',label = f'{round(reg.coef_[0],4)} year + {round(reg.intercept_,2)}')\n",
    "        plt.plot(time,time_analysis[analysis],'.',label = analysis)\n",
    "        plt.legend()\n",
    "        plt.xlabel('time [year]')\n",
    "        plt.title(analysis+' for '+name)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130ac9b-c308-47c7-843c-552e48c6c2a8",
   "metadata": {},
   "source": [
    "je sais pas si c'est plus parlant comme graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e6706-4b65-4c41-b86a-e2107e3ef23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WW2_analysis = time_analysis('WW2',ww2T)\n",
    "plot_time_analysis(WW2_analysis,'WW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd1bf6-d572-4baa-921f-aa3db63bc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('on average, the box office revenue is: ', WW2_analysis.mean_revenue.mean(), 'and the runtime is : ', WW2_analysis.mean_runtime.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc5180-1998-41a4-adee-0d50432d0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "Space_analysis = time_analysis('SpaceRace',SpaceT)\n",
    "plot_time_analysis(Space_analysis,'SpaceRace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9f3d8-bbc3-41cd-98a2-5c9f350b9feb",
   "metadata": {},
   "source": [
    "### Observe distribution and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242e28a-b55b-4bce-9a92-f74f67a52950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distr(name,tresh,xname,yname,glm=LinearRegression(),logy=False,axis=plt):\n",
    "#name : name of the historical event\n",
    "#tresh : treshold for accepting the movie as portraying the event\n",
    "#xname : name of the column we want on x axis\n",
    "#yname : name of the column we want on y axis\n",
    "#glm : glm method to use (https://scikit-learn.org/0.15/modules/linear_model.html)\n",
    "#logy : True if we want the y axis in log scale\n",
    "#axis : axis to plot on, default : plt for single figure\n",
    "\n",
    "    time_dist = movies_plot[movies_plot[name] > tresh]\n",
    "    if xname=='Release_date' or yname=='Release_date' :\n",
    "        pd.options.mode.chained_assignment = None  # default='warn' # get rid of warnings\n",
    "        time_dist['Release_date'] = pd.to_datetime(time_dist['Release_date']).dt.year\n",
    "        pd.options.mode.chained_assignment = 'warn'  # default='warn' # put warnings back\n",
    "    time_dist = time_dist.dropna()\n",
    "    Y = time_dist[yname]\n",
    "    if logy : \n",
    "        Y = Y.apply(lambda x : np.log(x))\n",
    "        yname = 'log '+ yname\n",
    "    X = np.array(time_dist[xname]).reshape(-1, 1)\n",
    "    \n",
    "    axis.plot(time_dist[xname],Y,'.',label = f'{name} movie')\n",
    "    \n",
    "    \n",
    "    reg = glm.fit(X,Y)\n",
    "    t = np.array(np.linspace(time_dist[xname].min(),time_dist[xname].max(),1000)).reshape(-1,1)\n",
    "    axis.plot(t,reg.predict(t),'-',label = str(glm))\n",
    "    \n",
    "    if axis == plt : #use Axes syntax\n",
    "        axis.legend()\n",
    "        axis.xlabel(xname)\n",
    "        axis.ylabel(yname)\n",
    "        axis.title(f'{yname} distribution for {name} event')\n",
    "    else : #use Axes.subplots syntax\n",
    "        axis.legend()\n",
    "        axis.set_xlabel(xname)\n",
    "        axis.set_ylabel(yname)\n",
    "        axis.set_title(f'{yname} distribution for {name} event')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distr('WW2',ww2T,'Release_date','Box_office_revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdeefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "plot_distr('WW2',ww2T,'Release_date','Box_office_revenue',axis=ax[0])\n",
    "plot_distr('WW2',ww2T,'Release_date','Box_office_revenue',logy=True,axis=ax[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede03a2-fe02-4b5b-9cb6-9f4722a72dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Movie Genres analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e5bf9-a7d5-403d-9230-862596b2059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_plot['Genres'] = movies_plot['Genres'].apply(lambda x: ', '.join(map(str, x)))\n",
    "movies_plot.Genres = movies_plot.Genres.apply(lambda h: h.lower())\n",
    "movies_plot.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8faf7-7b4b-4d9e-aa6c-5210b3df3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = []\n",
    "for genres in movies_plot['Genres']: #genres is a string of genres\n",
    "    for genre in genres.split(', '): #genre is a single genre\n",
    "        if genre not in genre_list:\n",
    "            genre_list.append(genre) #add genre to the list of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37415d-f383-4b7f-ba4d-db3fb6ff3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e0966-3850-4edd-9266-ef44a8bcc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c0e0d-fab2-432c-bf37-48e5b78b8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genres = ['Action', 'Adventure', 'Comedy', 'Fantasy', 'Historical', 'Horror', 'Satire', 'Science finction', 'Speculative',\n",
    "                 'Thriller', 'Western', 'Drama', 'Horror', 'Documentary', 'Musical', 'Romance','Mystery', 'War', 'Biography', 'History',\n",
    "                 'zombie film', 'Alien', 'Musical', 'anti-war', 'Black-and-white', 'Cold war', 'combat', 'Conspiration', 'crime', \n",
    "                'Documentary', 'Erotic', 'Gay', 'LGBT', 'Political', 'Romantic']\n",
    "movies_genres = [x.lower() for x in movies_genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91b44c-0096-4c91-a7ad-342b7acfb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in movies_genres:\n",
    "    movies_plot[genre] = movies_plot['Genres'].apply(lambda x: int(x.count(genre)>=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4022efc-f36c-4b0e-8fc6-66ea0cc6e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_genres = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0eb72-11f5-4323-ac2c-46b76223993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_genres['WW1'] = movies_plot[movies_plot['WW1'] > ww1T][movies_genres].sum()\n",
    "dictionnary_genres['WW2'] = movies_plot[movies_plot['WW2'] > ww2T][movies_genres].sum()\n",
    "dictionnary_genres['SpaceRace'] = movies_plot[movies_plot['SpaceRace'] > SpaceT][movies_genres].sum()\n",
    "dictionnary_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f0262-41f1-4445-97ed-952892843fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "heat_map = sns.heatmap( dictionnary_genres, linewidth = 1 , annot = True)\n",
    "plt.title( \"HeatMap between Genre and historical event\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a03b6b-f23a-45a0-a2f5-4a301ea8050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "erotique_analysis=time_analysis('Erotica', 0, freq='2y')\n",
    "gay_analysis=time_analysis('Gay', 0, freq='2y')\n",
    "lgbt_analysis=time_analysis('LGBT', 0, freq='2y')\n",
    "WW1_analysis=time_analysis('WW1', 0, freq='2y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d629b2-9ec3-4a61-a7bb-6b016d26e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "WW1_analysis.number.plot(grid=True, label=\"number of film WW1\", legend=True)\n",
    "WW2_analysis.number.plot(secondary_y=True, label=\"number of film WW2\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71072007-93ba-4f99-90b0-3c06804c1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "erotique_analysis.number.plot(grid=True, label=\"number of film erotique\", legend=True)\n",
    "WW2_analysis.number.plot(label=\"number of film WW2\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55702629-cec6-48f2-9ecd-279961df7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "gay_analysis.number.plot(label=\"number of film gay\", legend=True)\n",
    "lgbt_analysis.number.plot(label=\"number of film lgbt\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37961f47-4818-4960-b391-83ee064e2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_plot.Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec2ff4-e79e-4c6c-9e26-85c568367d56",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f606658-a719-43a0-912d-9baa139d0817",
   "metadata": {},
   "source": [
    "define our feature we will use in PCA and normalize. Could define more feature by introducing character information i.e. gender ratio, age, height etc.. just need computation and fusion of DF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee09023-4e59-4835-980f-ffe6f51b752c",
   "metadata": {},
   "source": [
    "-> start simple with 4 variables: box office, and the 3 events we have already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b75026-45f1-4eee-924f-9bac628722ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Box_office_revenue','WW1','WW2','SpaceRace']\n",
    "PCAfeature = movies_plot[features].dropna()\n",
    "PCAfeature= preprocessing.StandardScaler().fit(PCAfeature).transform(PCAfeature)\n",
    "print(np.mean(PCAfeature,axis = 0),np.std(PCAfeature,axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2304b-21b4-4f07-9a4c-5dd001c10f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)  \n",
    "projected = pca.fit_transform(PCAfeature)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "arrowprops = dict(arrowstyle='-',linewidth=2,shrinkA=0,shrinkB=0)\n",
    "\n",
    "for i,f in enumerate(features):\n",
    "    ax.annotate(f,[0,0],10*pca.components_[:,i],arrowprops= arrowprops)\n",
    "    \n",
    "plt.plot(projected[:, 0], projected[:, 1],'r.')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e6b79-cdab-4337-a7f5-fbec2f9069fc",
   "metadata": {},
   "source": [
    "## Kmean analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462647a7-877a-4c15-b7f8-0d867312c605",
   "metadata": {},
   "source": [
    "Same question here, which feature to take... For now, we will take the same as in the PCA section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0f5cf-87cf-4176-9b14-3bd8741231c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Box_office_revenue','WW1','WW2','SpaceRace']\n",
    "PCAfeature = movies_plot[features].dropna()\n",
    "PCAfeature= preprocessing.StandardScaler().fit(PCAfeature).transform(PCAfeature) #\n",
    "kmeans = KMeans(n_clusters=4, random_state=1).fit(PCAfeature)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa19741-aedb-4ba2-8f32-fb4c371b9311",
   "metadata": {},
   "source": [
    "We will plot the Kmean onto the 2 first PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42f48f-bc4f-4388-85f9-74670e19cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "arrowprops = dict(arrowstyle='-',linewidth=2,shrinkA=0,shrinkB=0)\n",
    "\n",
    "for i,f in enumerate(features):\n",
    "    ax.annotate(f,[0,0],10*pca.components_[:,i],arrowprops= arrowprops)\n",
    "    \n",
    "plt.scatter(projected[:, 0], projected[:, 1],c = kmeans.labels_)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f5129-fdad-47af-926f-259aa0cb0627",
   "metadata": {},
   "source": [
    "# Some vizualisation (Nono's excellent code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf16ea-60c6-4f0f-b95a-90eb00ced9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of movies in which a particular character type is present.\n",
    "values = []\n",
    "counts = []\n",
    "for v,c in merge_characters_type.groupby(by='Type') :\n",
    "    values += [v]\n",
    "    counts += [len(c)]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.vlines(values, 0, counts, color='C2', lw=4)\n",
    "plt.ylim(0,max(counts))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084084a0-c49a-41d0-82fd-2edfa6577ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean box office revenue of movies in which a particular character type is present.\n",
    "values = []\n",
    "counts = []\n",
    "for v,c in merge_characters_type.groupby(by='Type') :\n",
    "    values += [v]\n",
    "    counts += [c.Box_office_revenue.mean()]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.vlines(values, 0, counts, color='C1', lw=4)\n",
    "plt.ylim(0,max(counts))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16916501-8e38-4ef5-baa4-d45fada2aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_characters_type.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabf4af1-d377-43f5-a733-4aefd55fa117",
   "metadata": {},
   "source": [
    "look for the crazy jalouse guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377a480-cdb5-44ba-b908-b8788c8b7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crazy_jalouse_guy = merge_characters_type.loc[merge_characters_type['Type'].isin(['crazy_jealous_guy'])]\n",
    "Crazy_jalouse_guy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02cdd3-0d7a-4b7b-af10-861feb3d619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Crazy_jalouse_guy.groupby((pd.to_datetime(Crazy_jalouse_guy['Movie_release_date']).dt.to_period(freq='10Y'))).apply(lambda x: pd.Series({\n",
    "    'mean_height': x['Actor Height'].mean(),\n",
    "    'mean_age' : x['Age_at_movie_release'].mean(),\n",
    "    'mean_revenue' : x['Box_office_revenue'].mean(),\n",
    "    'mean_runtime' : x['Runtime'].mean(),\n",
    "    'number': x.Type.value_counts(), #verify that the number is not zero for a time period \n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb008e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472153f6-0424-4a96-86d9-08840610e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean age and mean height of crazy jealous guy depending on the movie release date\n",
    "b.mean_age.plot(grid=True, label=\"mean_age\", legend=True)\n",
    "b.mean_height.plot(secondary_y=True, label=\"mean_height\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673532a-c559-45e7-ad04-8b2ae413c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot mean revenue and mean runtime of movies with a crazy jealous guy depending on the movie release date\n",
    "b.mean_revenue.plot(grid=True, label=\"mean_revenue\", legend=True)\n",
    "b.mean_runtime.plot(secondary_y=True, label=\"mean_runtime\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431474af-ffff-4c0f-a032-ef2b890f6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crazy_jalous_guy.Actor_Ethnicity.value_counts() #mostly american"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261db7c-0250-4b81-80a5-9bf37359a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "Crazy_jalous_guy.movie.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a38b4-21a0-4c1c-a58d-c0e83e317b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='Age_at_movie_release', y='Actor_Gender', data=Crazy_jalouse_guy, logistic=True, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1c7a0-2bcb-4e44-80bc-10e00b7586de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
